{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge walk give jump drive bake the sleep night laugh and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking ornament holly jingle beard naughty nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking ornament holly jingle beard naughty nice sing cheer and of the is eat visit relax unwrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>hohoho candle poinsettia snowglobe peppermint eggnog fruitcake chocolate candy puzzle game doll toy workshop wonder believe dream hope peace joy merry season greeting card wrapping paper bow fireplace night cookie milk star wish wreath angel the to of and in that have it not with as you from we kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge walk give jump drive bake the sleep night laugh and yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking ornament holly jingle beard naughty nice sing cheer and of the is eat visit relax unwrap hohoho candle poinsettia snowglobe peppermint eggnog fruitcake chocolate candy puzzle game doll toy workshop wonder believe dream hope peace joy merry season greeting card wrapping paper bow fireplace night cookie milk star wish wreath angel the to of and in that have it not with as you from we kaggle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "2   2   \n",
       "3   3   \n",
       "4   4   \n",
       "5   5   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           text  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge walk give jump drive bake the sleep night laugh and  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking ornament holly jingle beard naughty nice  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                         yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking ornament holly jingle beard naughty nice sing cheer and of the is eat visit relax unwrap  \n",
       "4                                                                                                                                                                                                                                                                                                                                                hohoho candle poinsettia snowglobe peppermint eggnog fruitcake chocolate candy puzzle game doll toy workshop wonder believe dream hope peace joy merry season greeting card wrapping paper bow fireplace night cookie milk star wish wreath angel the to of and in that have it not with as you from we kaggle  \n",
       "5  advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge walk give jump drive bake the sleep night laugh and yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking ornament holly jingle beard naughty nice sing cheer and of the is eat visit relax unwrap hohoho candle poinsettia snowglobe peppermint eggnog fruitcake chocolate candy puzzle game doll toy workshop wonder believe dream hope peace joy merry season greeting card wrapping paper bow fireplace night cookie milk star wish wreath angel the to of and in that have it not with as you from we kaggle  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Loading spaCy's English language model \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# adjusting display options\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.read_csv('../Dataset/sample_submission.csv')\n",
    "n_rows = df.shape[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# # Tokenize the text and convert to lowercase\n",
    "# df['tokens'] = df['text'].apply(lambda x: word_tokenize(x.lower()))\n",
    "\n",
    "# # Display the tokenized words\n",
    "# print(\"Tokenized Data:\\n\", df.head())\n",
    "\n",
    "# # Save tokenized text to a text file\n",
    "# with open('tokenized_text.txt', 'w') as f:\n",
    "#     for tokens in df['tokens']:\n",
    "#         # Join the tokens back into a single string for each line\n",
    "#         line = ' '.join(tokens)\n",
    "#         f.write(line + '\\n')\n",
    "\n",
    "# print(\"Tokenized text saved to tokenized_text.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the text using spaCy\n",
    "def spacy_tokenize(text):\n",
    "    doc = nlp(text.lower())\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "df['tokens'] = df['text'].apply(spacy_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized text saved to tokenized_text.txt\n"
     ]
    }
   ],
   "source": [
    "# Saving the tokenized text to a text file\n",
    "with open('../Tokens/tokenized_text.txt', 'w') as f:\n",
    "    for tokens in df['tokens']:\n",
    "        line = ' '.join(tokens)\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "print(\"Tokenized text saved to tokenized_text.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Lines:\n",
      " [['advent', 'chimney', 'elf', 'family', 'fireplace', 'gingerbread', 'mistletoe', 'ornament', 'reindeer', 'scrooge'], ['advent', 'chimney', 'elf', 'family', 'fireplace', 'gingerbread', 'mistletoe', 'ornament', 'reindeer', 'scrooge', 'walk', 'give', 'jump', 'drive', 'bake', 'the', 'sleep', 'night', 'laugh', 'and'], ['yuletide', 'decorations', 'gifts', 'cheer', 'holiday', 'carol', 'magi', 'nutcracker', 'polar', 'grinch', 'sleigh', 'chimney', 'workshop', 'stocking', 'ornament', 'holly', 'jingle', 'beard', 'naughty', 'nice'], ['yuletide', 'decorations', 'gifts', 'cheer', 'holiday', 'carol', 'magi', 'nutcracker', 'polar', 'grinch', 'sleigh', 'chimney', 'workshop', 'stocking', 'ornament', 'holly', 'jingle', 'beard', 'naughty', 'nice', 'sing', 'cheer', 'and', 'of', 'the', 'is', 'eat', 'visit', 'relax', 'unwrap'], ['hohoho', 'candle', 'poinsettia', 'snowglobe', 'peppermint', 'eggnog', 'fruitcake', 'chocolate', 'candy', 'puzzle', 'game', 'doll', 'toy', 'workshop', 'wonder', 'believe', 'dream', 'hope', 'peace', 'joy', 'merry', 'season', 'greeting', 'card', 'wrapping', 'paper', 'bow', 'fireplace', 'night', 'cookie', 'milk', 'star', 'wish', 'wreath', 'angel', 'the', 'to', 'of', 'and', 'in', 'that', 'have', 'it', 'not', 'with', 'as', 'you', 'from', 'we', 'kaggle'], ['advent', 'chimney', 'elf', 'family', 'fireplace', 'gingerbread', 'mistletoe', 'ornament', 'reindeer', 'scrooge', 'walk', 'give', 'jump', 'drive', 'bake', 'the', 'sleep', 'night', 'laugh', 'and', 'yuletide', 'decorations', 'gifts', 'cheer', 'holiday', 'carol', 'magi', 'nutcracker', 'polar', 'grinch', 'sleigh', 'chimney', 'workshop', 'stocking', 'ornament', 'holly', 'jingle', 'beard', 'naughty', 'nice', 'sing', 'cheer', 'and', 'of', 'the', 'is', 'eat', 'visit', 'relax', 'unwrap', 'hohoho', 'candle', 'poinsettia', 'snowglobe', 'peppermint', 'eggnog', 'fruitcake', 'chocolate', 'candy', 'puzzle', 'game', 'doll', 'toy', 'workshop', 'wonder', 'believe', 'dream', 'hope', 'peace', 'joy', 'merry', 'season', 'greeting', 'card', 'wrapping', 'paper', 'bow', 'fireplace', 'night', 'cookie', 'milk', 'star', 'wish', 'wreath', 'angel', 'the', 'to', 'of', 'and', 'in', 'that', 'have', 'it', 'not', 'with', 'as', 'you', 'from', 'we', 'kaggle']]\n"
     ]
    }
   ],
   "source": [
    "# Loading the tokenized text from the file\n",
    "with open('../Tokens/tokenized_text.txt', 'r') as f:\n",
    "    tokenized_lines = [line.strip().split() for line in f]\n",
    "\n",
    "print(\"Tokenized Lines:\\n\", tokenized_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Vocabulary and Convert Sequences to Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences of Indices:\n",
      " [[0, 68, 16, 79, 41, 5, 76, 15, 81, 19], [0, 68, 16, 79, 41, 5, 76, 15, 81, 19, 42, 64, 38, 32, 66, 56, 73, 65, 12, 80], [69, 83, 82, 33, 8, 49, 43, 11, 24, 4, 46, 68, 70, 48, 15, 53, 78, 45, 61, 30], [69, 83, 82, 33, 8, 49, 43, 11, 24, 4, 46, 68, 70, 48, 15, 53, 78, 45, 61, 30, 84, 33, 80, 26, 56, 85, 27, 57, 39, 51], [17, 60, 47, 18, 58, 1, 44, 88, 71, 62, 34, 23, 7, 70, 52, 2, 77, 13, 86, 54, 36, 3, 35, 14, 9, 29, 6, 41, 65, 75, 40, 72, 10, 50, 21, 56, 63, 26, 80, 28, 67, 20, 31, 55, 37, 22, 59, 87, 74, 25], [0, 68, 16, 79, 41, 5, 76, 15, 81, 19, 42, 64, 38, 32, 66, 56, 73, 65, 12, 80, 69, 83, 82, 33, 8, 49, 43, 11, 24, 4, 46, 68, 70, 48, 15, 53, 78, 45, 61, 30, 84, 33, 80, 26, 56, 85, 27, 57, 39, 51, 17, 60, 47, 18, 58, 1, 44, 88, 71, 62, 34, 23, 7, 70, 52, 2, 77, 13, 86, 54, 36, 3, 35, 14, 9, 29, 6, 41, 65, 75, 40, 72, 10, 50, 21, 56, 63, 26, 80, 28, 67, 20, 31, 55, 37, 22, 59, 87, 74, 25]]\n"
     ]
    }
   ],
   "source": [
    "# Building vocabulary\n",
    "vocab = {word: i for i, word in enumerate(set(word for tokens in tokenized_lines for word in tokens))}\n",
    "\n",
    "# Convert sequences to indices\n",
    "indices_sequences = [[vocab[word] for word in tokens] for tokens in tokenized_lines]\n",
    "print(\"Sequences of Indices:\\n\", indices_sequences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded Sequences:\n",
      " [[ 0 68 16 79 41  5 76 15 81 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0]\n",
      " [ 0 68 16 79 41  5 76 15 81 19 42 64 38 32 66 56 73 65 12 80  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0]\n",
      " [69 83 82 33  8 49 43 11 24  4 46 68 70 48 15 53 78 45 61 30  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0]\n",
      " [69 83 82 33  8 49 43 11 24  4 46 68 70 48 15 53 78 45 61 30 84 33 80 26\n",
      "  56 85 27 57 39 51  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0]\n",
      " [17 60 47 18 58  1 44 88 71 62 34 23  7 70 52  2 77 13 86 54 36  3 35 14\n",
      "   9 29  6 41 65 75 40 72 10 50 21 56 63 26 80 28 67 20 31 55 37 22 59 87\n",
      "  74 25  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0]\n",
      " [ 0 68 16 79 41  5 76 15 81 19 42 64 38 32 66 56 73 65 12 80 69 83 82 33\n",
      "   8 49 43 11 24  4 46 68 70 48 15 53 78 45 61 30 84 33 80 26 56 85 27 57\n",
      "  39 51 17 60 47 18 58  1 44 88 71 62 34 23  7 70 52  2 77 13 86 54 36  3\n",
      "  35 14  9 29  6 41 65 75 40 72 10 50 21 56 63 26 80 28 67 20 31 55 37 22\n",
      "  59 87 74 25]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = max(len(tokens) for tokens in indices_sequences)\n",
    "padded_sequences = pad_sequences(indices_sequences, maxlen=max_len, padding='post')\n",
    "print(\"Padded Sequences:\\n\", padded_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded Sequences Shape: (6, 100)\n",
      "Extended Targets Shape: (6, 100, 89)\n"
     ]
    }
   ],
   "source": [
    "# Correct sequence (manually labeled)\n",
    "correct_sequence = [\"advent\", \"chimney\", \"fireplace\", \"family\", \"elf\", \"reindeer\", \"scrooge\", \"ornament\", \"mistletoe\", \"gingerbread\", \"walk\", \"drive\", \"bake\", \"give\", \"jump\", \"laugh\", \"sleep\", \"night\", \"the\", \"and\"]\n",
    "\n",
    "# Convert correct sequence to indices using the vocabulary\n",
    "correct_indices = [vocab[word] for word in correct_sequence]\n",
    "\n",
    "# Pad the correct indices to match the maximum sequence length\n",
    "padded_correct_indices = pad_sequences([correct_indices], maxlen=max_len, padding='post')[0]\n",
    "\n",
    "# One-hot encode the padded correct sequence\n",
    "def one_hot_encode_sequence(sequence, vocab_size):\n",
    "    one_hot = np.zeros((len(sequence), vocab_size))\n",
    "    for i, index in enumerate(sequence):\n",
    "        one_hot[i, index] = 1\n",
    "    return one_hot\n",
    "\n",
    "one_hot_target = one_hot_encode_sequence(padded_correct_indices, len(vocab))\n",
    "\n",
    "# Ensure the extended targets have the correct shape\n",
    "extended_targets = np.array([one_hot_target] * len(padded_sequences))\n",
    "\n",
    "print(\"Padded Sequences Shape:\", padded_sequences.shape)\n",
    "print(\"Extended Targets Shape:\", extended_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mebub_9a7jdi8\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 100, 89), output.shape=(None, 89)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;28mlen\u001b[39m(vocab), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextended_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:580\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must be at least rank 1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m     )\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m--> 580\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(ndim). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    583\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    584\u001b[0m     )\n\u001b[0;32m    585\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
      "\u001b[1;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 100, 89), output.shape=(None, 89)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Defining the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(vocab), output_dim=128, input_length=max_len))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(vocab), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(padded_sequences, extended_targets, epochs=10, batch_size=32)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
